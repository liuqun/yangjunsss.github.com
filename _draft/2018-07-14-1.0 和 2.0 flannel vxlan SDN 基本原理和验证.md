---
description: "
SDN 改变了传统的网络世界，在 Underlay 之上构建 Overlay 灵活性带来了巨大的红利，如[fastly成本案例](https://www.fastly.com/blog/building-and-scaling-fastly-network-part-1-fighting-fib)。在容器生态中，[Flannel](https://github.com/coreos/Flannel/)为容器集群构建 Overlay 网络。目前网上大多数文章还是介绍的 Flannel 第一代 vxlan 实现原理，本文介绍 Flannel 第一代和第二代 Flannel vxlan 两种方式的基本原理。如有错误，感谢指正，共同学习；）
"
---

### 摘要

SDN 改变了传统的网络世界，在 Underlay 之上构建 Overlay 灵活性带来了巨大的红利，如[fastly成本案例](https://www.fastly.com/blog/building-and-scaling-fastly-network-part-1-fighting-fib)。在容器生态中，[Flannel](https://github.com/coreos/Flannel/)为容器集群构建三层 Overlay 网络。目前网上大多数文章还是介绍的 Flannel 第一代 vxlan 实现原理，本文介绍 Flannel 第一代和第二代 Flannel vxlan 两种方式的基本原理。如有错误，感谢指正，共同学习；）

### Flannel vxlan 核心设计和历史

关于 vxlan 的知识网上很多，简单来是在 Underlay 网络之上使用 UDP 和隧道技术构建的 Overlay 的逻辑网络，依托传输层 UDP 协议，三层穿透 Underlay 网络，使逻辑网络与物理网络解耦，实现灵活的组网需求，不仅仅能适配 VM 虚拟机环境，还能作用于 Container 容器环境。

这里网络数据包转发的核心是 RIB 路由表、FDB 转发表、ARP 路由表，即 vxlan 要解决二层 Guest MAC 地址寻址、跨三层 Guest IP 地址寻址的问题，并实现全网高效路由分发和同步，这里讨论容器生态中 Flannel 的实现方案。

在最新的 Flannel vxlan 代码 [vxlan.go](https://github.com/coreos/Flannel/blob/master/backend/vxlan/vxlan.go) 官方有一段注释说明如下：

```text

// Some design notes and history:
// vxlan encapsulates L2 packets (though Flannel is L3 only so don't expect to be able to send L2 packets across hosts)
// The first versions of vxlan for Flannel registered the Flannel daemon as a handler for both "L2" and "L3" misses
// - When a container sends a packet to a new IP address on the Flannel network (but on a different host) this generates
//   an L2 miss (i.e. an ARP lookup)
// - The Flannel daemon knows which Flannel host the packet is destined for so it can supply the VTEP MAC to use.
//   This is stored in the ARP table (with a timeout) to avoid constantly looking it up.
// - The packet can then be encapsulated but the host needs to know where to send it. This creates another callout from
//   the kernal vxlan code to the Flannel daemon to get the public IP that should be used for that VTEP (this gets called
//   an L3 miss). The L2/L3 miss hooks are registered when the vxlan device is created. At the same time a device route
//   is created to the whole Flannel network so that non-local traffic is sent over the vxlan device.
//
// In this scheme the scaling of table entries (per host) is:
//  - 1 route (for the configured network out the vxlan device)
//  - One arp entry for each remote container that this host has recently contacted
//  - One FDB entry for each remote host
//
// The second version of Flannel vxlan removed the need for the L3MISS callout. When a new remote host is found (either
// during startup or when it's created), Flannel simply adds the required entries so that no further lookup/callout is required.
//
//
// The latest version of the vxlan backend  removes the need for the L2MISS too, which means that the Flannel deamon is not
// listening for any netlink messages anymore. This improves reliability (no problems with timeouts if
// Flannel crashes or restarts) and simplifies upgrades.
//
// How it works:
// Create the vxlan device but don't register for any L2MISS or L3MISS messages
// Then, as each remote host is discovered (either on startup or when they are added), do the following
// 1) create routing table entry for the remote subnet. It goes via the vxlan device but also specifies a next hop (of the remote Flannel host).
// 2) Create a static ARP entry for the remote Flannel host IP address (and the VTEP MAC)
// 3) Create an FDB entry with the VTEP MAC and the public IP of the remote Flannel daemon.
//
// In this scheme the scaling of table entries is linear to the number of remote hosts - 1 route, 1 arp entry and 1 FDB entry per host
```

大致意思：

  1. 第一代 vxlan 依赖 vxlan L2 和 L3 Miss 监听事件来实现 Container ARP 和 FDB 路由表的更新，但可靠性和效率不高；
  2. 第二代 vxlan 实现采用三层路由的方式实现，并使路由个数与物理机器成线性关系，提高可靠性和性能；

### L2&L3 Miss vxlan 实现方案

#### 理论基础

L2 和 L3 Miss 依赖 Kernel 内核的 vxlan DOVE 机制，当 vxlan 无法在 FDB 转发数据库中找到对应的 MAC 地址转发目的地时发生 L2 Miss 通知事件，当在 ARP 表中找不到对应 IP-MAC 记录时发生 L3 Miss 通知事件。 Kernel 的 Commit 如下：

add DOVE extensions for vxlan
This patch provides extensions to vxlan for supporting Distributed Overlay Virtual Ethernet (DOVE) networks. The patch includes:

	+ a dove flag per vxlan device to enable DOVE extensions
	+ ARP reduction, whereby a bridge-connected vxlan tunnel endpoint answers ARP requests from the local bridge on behalf of remote DOVE clients
	+ route short-circuiting (aka L3 switching). Known destination IP addresses use the corresponding destination MAC address for switching rather than going to a (possibly remote) router first.
	+ netlink notification messages for forwarding table and L3 switching misses

```c
// L2 Miss - find dest from MAC in FDB
+	f = vxlan_find_mac(vxlan, eth->h_dest);
+	if (f == NULL) {
+		did_rsc = false;
+		dst = vxlan->gaddr;
+		if (!dst && (vxlan->flags & vxlan_F_L2MISS) &&
+		    !is_multicast_ether_addr(eth->h_dest))
+			vxlan_fdb_miss(vxlan, eth->h_dest);
+	}
```

```c
// L3 Miss - find MAC from IP in ARP Table
+	n = neigh_lookup(&arp_tbl, &tip, dev);
+
+	if (n) {...}
+ else if (vxlan->flags & vxlan_F_L3MISS)
+		vxlan_ip_miss(dev, tip);
```

可以看到内核在查询 `vxlan_find_mac` FDB 转发时未命中则发送 l2miss netlink 通知，在查询 `neigh_lookup` ARP 表时未命中则发送 l3miss netlink 通知，以便有机会给用户态补充路由，这就是第一代 Flannel vxlan 的实现基础。

模拟组网：

![img](/images/flannel_vxlan_1.0_impl.png)

流程：

  1. 当 Guest0 第一次发送一个目的地址 `10.20.1.3` 数据包的时候，判断为二层转发，查询本地 Guest ARP 表，无记录则发送 ARP 广播 `who is 10.20.1.3`；
  2. vxlan 开启了的本地 ARP 代答 proxy、l3miss 功能，数据包（实验 br 和 vtep 分离，验证 eth0 是否有 arp 广播）经过 vtep0 逻辑设备时，当 Host ARP 表无记录时，vxlan 触发 L2 Miss 事件，ARP 表是用于三层 IP 进行二层 MAC 转发的映射表，存储着 IP-MAC-NIC 记录，在二层转发过程中往往需要根据 IP 地址查询对应的 MAC 地址从而通过数据链路转发到目的接口中；
  3. L2 Miss 事件被 Flannel Daemon 捕捉到，Daemon 根据自身的 Etcd 存储的路由数据库返回 `10.20.1.3` 的 MAC 地址 `e6:4b:f9:ce:d7:7b` 并存储 Host ARP 表；
  4. vtep0 命中 ARP 记录后回复 ARP Reply；
  5. Guest0 收到 ARP Reply 后存 Guest ARP 表，开始发送数据，携带目的 `e6:4b:f9:ce:d7:7b` 地址；
  6. 数据包经过 bridge 时查询 FDB（Forwarding Database entry） 转发表，询问 where `e6:4b:f9:ce:d7:7b` send to? 如未命中记录，发生 L3 Miss 事件，FDB 表为 2 层交换机的转发表，FDB 存储这 MAC-PORT 的映射关系，用于 MAC数据包从哪个接口出；
  7. Flannel Daemon 捕捉 L3 Miss 事件，并向 FDB 表中加入目的 `e6:4b:f9:ce:d7:7b` 的数据包发送给对端 Host `192.168.100.3` 这台机器；
  8. 此时 `e6:4b:f9:ce:d7:7b` 数据包流向 vtep0 接口，vtep0 开始进行 UDP 封装，并填充 VNI 号为 1，并与对端 `192.168.100.3` 建立隧道，对端收到 vxlan 包进行拆分，根据 VNI 分发 vtep ，拆分后重新转回 Bridge，Bridge 根据 dst mac 地址转发到对应的 veth 接口上，此时就完成了整个数据包的转发；
  9. 配置回程路由；

#### 模拟验证

环境：

  1. 2 台 Centos7.x 机器，2 张物理网卡
  2. 2 个 Bridge，2 张 vtep 网卡
  3. 2 个 Namespace，2 对 veth 接口

步骤：

  1. 创建 Namespace 网络隔离空间模拟 Guest 环境
  2. 创建 veth 接口、Bridge 虚拟交换机、vtep 接口
  3. 验证 L2 和 L3 Miss 通知事件
  4. 配置路由
  5. 验证连通性，Guest0 ping Guest1，Guest0 ping Guest2

##### 准备环境

```sh
# HOST0
[root@i-7dlclo08 ~]# ip -d a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 52:54:ca:9d:db:ff brd ff:ff:ff:ff:ff:ff promiscuity 0
    inet 192.168.100.2/24 brd 192.168.100.255 scope global dynamic eth0
       valid_lft 24182sec preferred_lft 24182sec
    inet6 fe80::76ef:824d:95ef:18a3/64 scope link
       valid_lft forever preferred_lft forever
48: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP qlen 1000
    link/ether 5a:5f:4f:3c:4d:a6 brd ff:ff:ff:ff:ff:ff promiscuity 0
    bridge forward_delay 1500 hello_time 200 max_age 2000
    inet 10.20.1.1/24 scope global br0
       valid_lft forever preferred_lft forever
    inet6 fe80::585f:4fff:fe3c:4da6/64 scope link
       valid_lft forever preferred_lft forever
50: veth0@if49: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br0 state UP qlen 1000
    link/ether 82:17:03:c5:a5:bf brd ff:ff:ff:ff:ff:ff link-netnsid 1 promiscuity 1
    veth
    bridge_slave
    inet6 fe80::8017:3ff:fec5:a5bf/64 scope link
       valid_lft forever preferred_lft forever
51: vtep0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master br0 state UNKNOWN qlen 1000
    link/ether 52:2d:1f:cb:13:55 brd ff:ff:ff:ff:ff:ff promiscuity 1
    vxlan id 1 dev eth0 srcport 0 0 dstport 4789 nolearning proxy l2miss l3miss ageing 300
    bridge_slave

# HOST1
[root@i-hh5ai710 ~]# ip -d a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 52:54:d5:9b:94:4c brd ff:ff:ff:ff:ff:ff promiscuity 0
    inet 192.168.100.3/24 brd 192.168.100.255 scope global dynamic eth0
       valid_lft 30286sec preferred_lft 30286sec
    inet6 fe80::baef:a34c:3194:d36e/64 scope link
       valid_lft forever preferred_lft forever
87: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP qlen 1000
    link/ether d6:ca:34:af:d7:fd brd ff:ff:ff:ff:ff:ff promiscuity 0
    bridge forward_delay 1500 hello_time 200 max_age 2000
    inet 10.20.1.1/24 scope global br0
       valid_lft forever preferred_lft forever
    inet6 fe80::d4ca:34ff:feaf:d7fd/64 scope link
       valid_lft forever preferred_lft forever
89: veth0@if88: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br0 state UP qlen 1000
    link/ether 42:3b:18:50:10:d6 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 1
    veth
    bridge_slave
    inet6 fe80::403b:18ff:fe50:10d6/64 scope link
       valid_lft forever preferred_lft forever
90: vtep0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue master br0 state UNKNOWN qlen 1000
    link/ether 52:2f:17:7c:bc:0f brd ff:ff:ff:ff:ff:ff promiscuity 1
    vxlan id 1 dev eth0 srcport 0 0 dstport 4789 nolearning proxy l2miss l3miss ageing 300
    bridge_slave
```

ip link delete veth0
ip link delete vtep0
ip link delete br0
ip link add br0 type bridge
ip link set br0 address 5a:5f:4f:3c:4d:a6
ip link set br0 up
ip addr add 10.20.1.1/24 dev br0
ip link add veth0 type veth peer name veth0-0
ip link set dev veth0 up
ip link set dev veth0 master br0
ip link set dev veth0-0 netns ns0
ip netns exec ns0 ip link set lo up
ip netns exec ns0 ip link set veth0-0 name eth0
ip netns exec ns0 ip addr add 10.20.1.4/24 dev eth0
ip netns exec ns0 ip link set eth0 address ee:35:0f:11:73:b3
ip netns exec ns0 ip link set eth0 up
ip netns exec ns0 ip route add default via 10.20.1.1 dev eth0
ip link add vtep0 type vxlan id 1 dstport 4789 dev eth0 nolearning proxy l2miss l3miss
ip link set vtep0 address 52:2d:1f:cb:13:55
ip addr add 10.20.1.0/32 dev vtep0
ip link set vtep0 up


ip link delete veth0
ip link delete vtep0
ip link delete br0
ip link add br0 type bridge
ip link set br0 address d6:ca:34:af:d7:fd
ip link set br0 up
ip addr add 10.20.2.1/24 dev br0
ip link add veth0 type veth peer name veth0-0
ip link set dev veth0 up
ip link set dev veth0 master br0
ip link set dev veth0-0 netns ns0
ip netns exec ns0 ip link set lo up
ip netns exec ns0 ip link set veth0-0 name eth0
ip netns exec ns0 ip addr add 10.20.2.4/24 dev eth0
ip netns exec ns0 ip link set eth0 address e6:4b:f9:ce:d7:7b
ip netns exec ns0 ip link set eth0 up
ip netns exec ns0 ip route add default via 10.20.2.1 dev eth0
ip link add vtep0 type vxlan id 1 dstport 4789 dev eth0 nolearning proxy l2miss l3miss
ip link set vtep0 address 52:2f:17:7c:bc:0f
ip link set vtep0 up
# ip link set vtep0 master br0
ip addr add 10.20.2.0/32 dev vtep0



ip n add 10.20.2.0 lladdr 52:2f:17:7c:bc:0f dev vtep0
bridge fdb add 52:2f:17:7c:bc:0f dst 192.168.100.3 dev vtep0 vni 1
ip route add 10.20.2.0/24 via 10.20.2.0 dev vtep0 onlink

ip n add 10.20.1.0 lladdr 52:2d:1f:cb:13:55 dev vtep0
bridge fdb add 52:2d:1f:cb:13:55 dst 192.168.100.2 dev vtep0 vni 1
ip route add 10.20.1.0/24 via 10.20.1.0 dev vtep0 onlink





##### 观察 L2 和 L3 Miss 通知事件

```sh
# HOST0 10.20.1.4 ping 10.20.1.3
[root@i-7dlclo08 ~]# ip netns exec ns0 ping 10.20.1.3
PING 10.20.1.3 (10.20.1.3) 56(84) bytes of data.
From 10.20.1.4 icmp_seq=1 Destination Host Unreachable
From 10.20.1.4 icmp_seq=2 Destination Host Unreachable
From 10.20.1.4 icmp_seq=3 Destination Host Unreachable

# See L3 & L2 Miss
[root@i-7dlclo08 ~]# ip monitor all
[nsid current]miss 10.20.1.3 dev vtep0  STALE
[nsid current]miss 10.20.1.3 dev vtep0  STALE
[nsid current]miss 10.20.1.3 dev vtep0  STALE
[nsid 1]10.20.1.3 dev if49  FAILED
```

当缺失 ARP 记录时触发`[nsid 1]10.20.1.3 dev if45  FAILED`，当缺失 FDB 转发记录时触发`[nsid current]miss dev vtep0 lladdr e6:4b:f9:ce:d7:7b STALE`，并且网络不通。

##### 配置路由

```sh
[root@i-7dlclo08 ~]# ip n add 10.20.1.3 lladdr e6:4b:f9:ce:d7:7b dev vtep0
[root@i-7dlclo08 ~]# bridge fdb add e6:4b:f9:ce:d7:7b dst 192.168.100.3 dev vtep0
```

回程路由类似，不赘述

##### 测试连通性

`10.20.1.4 ping 10.20.1.3`
```sh
[root@i-7dlclo08 ~]# ip netns exec ns0 ping 10.20.1.3
PING 10.20.1.3 (10.20.1.3) 56(84) bytes of data.
64 bytes from 10.20.1.3: icmp_seq=1 ttl=64 time=1.04 ms
64 bytes from 10.20.1.3: icmp_seq=2 ttl=64 time=0.438 ms
```
配置好对端 Guest 路由后，网络连通成功。

#### L2 和 L3 Miss 方案缺陷

1. 每一台 Host 需要配置所有需要互通 Guest 的路由，路由记录膨胀，不适合大型组网
2. 通过 netlink 通知查询路由的效率不高
3. 部分 Flannel Daemon 异常后会导致 Guest 之间的互通


### 远端路由 vxlan 实现方案

#### 理论基础

组网：
![img](/images/flannel_vxlan_2.0_impl.png)

在最新的 Flannel vxlan 实现上，Flannel 把 L2MISS & L3MISS 去掉了，Flannel deamon 不再监听 netlink 通知，而是通过给目的子网添加远端 HOST 路由的方式实现数据转发，并且给 vtep 分配一个三层地址，这样的好处就是 HOST 不需要配置所有的 Guest 的路由，而只需配置好目的子网与对应 HOST 路由就可以了，这种方式的路由记录与 HOST 机器线性相关，官方声称做到每一台主机 1 route，1 arp entry and 1 FDB entry。

#### 模拟验证

环境：

  1. 2 台 Centos7.x 机器，2张网卡
  2. 2 个 Bridge，2 张 vtep 网卡
  3. 2 个 Namespace，2 对 veth 接口

步骤：

  1. 创建 Namespace 网络隔离空间模拟 Guest 环境
  2. 创建 veth 接口、Bridge 虚拟交换机、vtep 接口
  3. 验证 L2 和 L3 Miss 通知事件
  4. 配置路由
  5. 验证连通性，Guest0 ping Guest1，Guest0 ping Guest2

##### 准备环境

```sh
# HOST0 网络配置接口
[root@i-7dlclo08 ~]# ip -d a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 52:54:ca:9d:db:ff brd ff:ff:ff:ff:ff:ff promiscuity 0
    inet 192.168.100.2/24 brd 192.168.100.255 scope global dynamic eth0
       valid_lft 43081sec preferred_lft 43081sec
    inet6 fe80::76ef:824d:95ef:18a3/64 scope link
       valid_lft forever preferred_lft forever
60: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP qlen 1000
    link/ether 5a:5f:4f:3c:4d:a6 brd ff:ff:ff:ff:ff:ff promiscuity 0
    bridge forward_delay 1500 hello_time 200 max_age 2000
    inet 10.20.1.1/24 scope global br0
       valid_lft forever preferred_lft forever
    inet6 fe80::585f:4fff:fe3c:4da6/64 scope link
       valid_lft forever preferred_lft forever
62: veth0@if61: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br0 state UP qlen 1000
    link/ether 92:6d:63:de:28:d2 brd ff:ff:ff:ff:ff:ff link-netnsid 1 promiscuity 1
    veth
    bridge_slave
    inet6 fe80::906d:63ff:fede:28d2/64 scope link
       valid_lft forever preferred_lft forever
63: vtep0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN qlen 1000
    link/ether 52:2d:1f:cb:13:55 brd ff:ff:ff:ff:ff:ff promiscuity 0
    vxlan id 1 dev eth0 srcport 0 0 dstport 4789 nolearning proxy l2miss l3miss ageing 300
    inet 10.20.1.0/32 scope global vtep0
       valid_lft forever preferred_lft forever

# HOST1 网络配置接口
[root@i-hh5ai710 ~]# ip -d a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 52:54:d5:9b:94:4c brd ff:ff:ff:ff:ff:ff promiscuity 0
    inet 192.168.100.3/24 brd 192.168.100.255 scope global dynamic eth0
       valid_lft 29412sec preferred_lft 29412sec
    inet6 fe80::baef:a34c:3194:d36e/64 scope link
       valid_lft forever preferred_lft forever
95: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP qlen 1000
    link/ether d6:ca:34:af:d7:fd brd ff:ff:ff:ff:ff:ff promiscuity 0
    bridge forward_delay 1500 hello_time 200 max_age 2000
    inet 10.20.2.1/24 scope global br0
       valid_lft forever preferred_lft forever
    inet6 fe80::d4ca:34ff:feaf:d7fd/64 scope link
       valid_lft forever preferred_lft forever
97: veth0@if96: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br0 state UP qlen 1000
    link/ether a6:cc:5b:a4:54:d3 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 1
    veth
    bridge_slave
    inet6 fe80::a4cc:5bff:fea4:54d3/64 scope link
       valid_lft forever preferred_lft forever
98: vtep0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN qlen 1000
    link/ether 52:2f:17:7c:bc:0f brd ff:ff:ff:ff:ff:ff promiscuity 0
    vxlan id 1 dev eth0 srcport 0 0 dstport 4789 nolearning proxy l2miss l3miss ageing 300
    inet 10.20.2.0/32 scope global vtep0
       valid_lft forever preferred_lft forever
```

##### 路由配置

```sh
# One Route
10.20.2.0/24 via 10.20.2.0 dev vtep0 onlink
# One ARP
10.20.2.0 dev vtep0 lladdr 52:2f:17:7c:bc:0f PERMANENT
# One FDB
52:2f:17:7c:bc:0f dev vtep0 dst 192.168.100.3 self permanent
```
回程路由类似。

##### 测试连通性

`10.20.1.4 ping 10.20.2.4`

```sh
[root@i-7dlclo08 ~]# ip netns exec ns0 ping 10.20.2.4
PING 10.20.2.4 (10.20.2.4) 56(84) bytes of data.
64 bytes from 10.20.2.4: icmp_seq=1 ttl=62 time=0.992 ms
64 bytes from 10.20.2.4: icmp_seq=2 ttl=62 time=0.518 ms
```

通过增加一条远端路由 `10.20.2.0/24 via 10.20.2.0 dev vtep0 onlink` 使目标为 10.20.2.0/24 的目的 IP 包通过 vtep 接口送往目的 HOST，目的 HOST 收到后，在本地 HOST 做三层转发，最终送往 veth0 接口。在 HOST 多个 Guest 场景下也无需额外配置 Guest 路由，从而大量减少了路由数量。

### 总结
以上就是对 Flannel 1.0 和 2.0 vxlan 实现基本原理的解析和验证，可以看到 SDN 的 Overlay 配置很灵活也很巧妙，基本 Overlay 的数据包通过 vxlan 这种技术穿透 Underlay 网络，同时主机中迭代着两层网络配置带来了一定的复杂性，但最终无论方案如何变化都离不开二三层路由转发的基本原则。

##### 附录

[Linux 上实现 vxlan 网络](http://cizixs.com/2017/09/28/linux-vxlan)

[Kernel Map](http://www.makelinux.net/kernel_map/)

[Network Stack](http://www.cs.dartmouth.edu/~sergey/io/netreads/path-of-packet/Network_stack.pdf)

[Packet Flow](https://www.ccnahub.com/ip-fundamentals/understanding-packet-flow-across-the-network-part1/)

[TCP/IP Network Stack](https://www.cubrid.org/blog/understanding-tcp-ip-network-stack)
